{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6d11ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rgb2gray\n\u001b[0;32m      7\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHarsh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool_Practicals\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCV_Image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#Load path of image and ensure you provide the img name at the end with the file type(.jpg, .png, etc.)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m img1 \u001b[38;5;241m=\u001b[39m \u001b[43mrgb2gray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#Grayscale using skimage\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHarsh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool_Practicals\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCV_Image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#Grayscale using cv2\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#BGR\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py:394\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:875\u001b[0m, in \u001b[0;36mrgb2gray\u001b[1;34m(rgb, channel_axis)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;129m@channel_as_last_axis\u001b[39m(multichannel_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrgb2gray\u001b[39m(rgb, \u001b[38;5;241m*\u001b[39m, channel_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute luminance of an RGB image.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m    >>> img_gray = rgb2gray(img)\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m     rgb \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_colorarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.2125\u001b[39m, \u001b[38;5;241m0.7154\u001b[39m, \u001b[38;5;241m0.0721\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mrgb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rgb \u001b[38;5;241m@\u001b[39m coeffs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:137\u001b[0m, in \u001b[0;36m_prepare_colorarray\u001b[1;34m(arr, force_copy, channel_axis)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"Check the shape of the array and convert it to\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03mfloating point representation.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    138\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe input array must have size 3 along `channel_axis`, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    139\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "img = cv2.imread(r'C:\\Users\\91776\\OneDrive\\Desktop\\HP\\Python\\School_Practicals\\CV_Image.jpg') #Load path of image and ensure you provide the img name at the end with the file type(.jpg, .png, etc.)\n",
    "img1 = rgb2gray(img)  #Grayscale using skimage\n",
    "img2 = cv2.imread(r'C:\\Users\\91776\\OneDrive\\Desktop\\HP\\Python\\School_Practicals\\CV_Image.jpg',0) #Grayscale using cv2\n",
    "\n",
    "#BGR\n",
    "plt.imshow(img)\n",
    "plt.title('BGR')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#RGB\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('RGB')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Grayscale\n",
    "#Using skimage conversion\n",
    "plt.imshow(img1, cmap = plt.cm.gray)\n",
    "plt.title('Grayscale skimage')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#Using cv2 conversion\n",
    "plt.imshow(img2, cmap = 'gray') #cmap specifies color mapping, gray in this case.\n",
    "plt.title('Grayscale cv2')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('')\n",
    "#Size of img\n",
    "print(img.shape)\n",
    "print('')\n",
    "print(img1.shape)#When loaded as grayscale note there are no color channels for grayscale img\n",
    "print('')\n",
    "#minimum and maximum pixel value present in the image\n",
    "print (img.min())\n",
    "print (img.max())\n",
    "print('')\n",
    "\n",
    "#Splitting Color Channel\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB));plt.axis('off');plt.title('RGB')\n",
    "b = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "r = img[:,:,2]\n",
    "fig, bgr = plt.subplots(1,3)\n",
    "bgr[0].imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB));bgr[0].axis('off');bgr[0].set_title('blue');\n",
    "bgr[1].imshow(cv2.cvtColor(g, cv2.COLOR_BGR2RGB));bgr[1].axis('off');bgr[1].set_title('green');\n",
    "bgr[2].imshow(cv2.cvtColor(r, cv2.COLOR_BGR2RGB));bgr[2].axis('off');bgr[2].set_title('red');\n",
    "plt.show()\n",
    "\n",
    "#Resizing\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Pic')\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "print('')\n",
    "roi = img[100:200,300:640] #img[range of y, range of x]\n",
    "plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Cropped_Pic')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(img, (200, 200))\n",
    "plt.imshow(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Tree')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized=cv2.resize(img,(int(img.shape[1]/4),int(img.shape[0]/4)))\n",
    "plt.imshow(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Tree')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = img[100:200,300:640]\n",
    "img[100:200,0:340]=img[200:300,100:440]=img[200:300,100:440]=tree\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('more trees')\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce5d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
